{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266fc8f6",
   "metadata": {},
   "source": [
    "# 6D Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b41fabe",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88aaa0",
   "metadata": {},
   "source": [
    "LineMOD dataset: https://drive.google.com/drive/folders/19ivHpaKm9dOrr12fzC8IDFczWRPFxho7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8012bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_ML = False # se True il notebook si connette a comet.ml per registrare i risultati degli esperimenti; serve un chiave API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542aceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da usare appena apro il notebook colab\n",
    "!git clone https://github.com/luigiaceto/6D-pose-estimation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 6D-pose-estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da eseguire SOLO SE mentre sto su colab ho pushato modifiche nella repo\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdb879",
   "metadata": {},
   "source": [
    "Install all PyTorch dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'installazione di PyTorch cambia a seconda dell'hardware su cui viene eseguita.\n",
    "# Mettendolo nei requirements si installa solo la versione CPU/default.\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7f2c7",
   "metadata": {},
   "source": [
    "Install all packages, you may need to restart the runtime before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt\n",
    "print(\"Restart runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b556090",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import watch\n",
    "\n",
    "from utils.data_exploration import load_image\n",
    "\n",
    "from data.CustomDatasetPose import IMG_WIDTH, IMG_HEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba70be",
   "metadata": {},
   "source": [
    "Set seed and device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.init import set_seed\n",
    "from utils.init import set_device\n",
    "\n",
    "set_seed(42)\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd806248",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d65714",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p datasets/linemod\n",
    "%cd datasets/linemod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93705fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --folder \"https://drive.google.com/drive/folders/1xEHOOLrkLD814mA9cJqM2kZ-vn35Zr7s?usp=drive_link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd DenseFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Linemod_preprocessed.zip\n",
    "!rm Linemod_preprocessed.zip\n",
    "!rm -f trained_checkpoints.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torno alla cartella root del progetto\n",
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590fb52",
   "metadata": {},
   "source": [
    "Get working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print working directory\n",
    "path = !pwd\n",
    "path = path[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02773553",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7f9e4",
   "metadata": {},
   "source": [
    "Copy ground truth files to ```Linemod_preprocessed```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import get_class_names\n",
    "from utils.preprocessing import copy_gt_file, change_02gt, quaternion_gt\n",
    "\n",
    "folder_names = get_class_names()\n",
    "copy_gt_file(folder_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add824a",
   "metadata": {},
   "source": [
    "Change ```02_gt.yml``` to take only one object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701bb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_02gt(\"./datasets/linemod/DenseFusion/Linemod_preprocessed/02_gt.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e793c4",
   "metadata": {},
   "source": [
    "Add quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c090358",
   "metadata": {},
   "outputs": [],
   "source": [
    "quaternion_gt(\"./datasets/linemod/DenseFusion/Linemod_preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb7108",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e3ec7",
   "metadata": {},
   "source": [
    "Load an image to check if it's all ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b121399",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_image(label=1, object=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ce9fc",
   "metadata": {},
   "source": [
    "## Define CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7160a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.CustomDatasetPose import CustomDatasetPose\n",
    "from utils.data_exploration import get_camera_intrinsics\n",
    "\n",
    "dataset_root = \"./datasets/linemod/DenseFusion/Linemod_preprocessed/\"\n",
    "\n",
    "cam_K = get_camera_intrinsics(dataset_root)\n",
    "\n",
    "train_dataset = CustomDatasetPose(dataset_root, split=\"train\", device=device, cam_K = cam_K)\n",
    "image_mean, image_std = train_dataset.get_image_mean_std()\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "\n",
    "val_dataset = CustomDatasetPose(dataset_root, split=\"validation\", device=device, cam_K = cam_K, img_mean = image_mean, img_std = image_std)\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "test_dataset = CustomDatasetPose(dataset_root, split=\"test\", device=device, cam_K = cam_K, img_mean = image_mean, img_std = image_std)\n",
    "print(f\"Testing samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b3ba",
   "metadata": {},
   "source": [
    "## Data Preprocessing for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d182a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_dataset.get_samples_id()\n",
    "validation_samples = val_dataset.get_samples_id()\n",
    "test_samples = test_dataset.get_samples_id() # test folder is optional for training YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6253d1e",
   "metadata": {},
   "source": [
    "Create a new folder containing all the info for YOLO, we just need the rgb image and a text file with the label and bounding box.\n",
    "The ```Linemod_preprocessed``` is not removed, as it contains info about translation and rotation that are needed for pose estimation, but not for YOLO object detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76389b",
   "metadata": {},
   "source": [
    "Create YOLO yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec539f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import create_YOLO_yaml, create_dataset_YOLO\n",
    "\n",
    "number_classes, class_names = create_YOLO_yaml(path, folder_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ba3d0",
   "metadata": {},
   "source": [
    "While creating the folder structure, we have to change the class id by using the index in the array written in the ```data.yaml```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to have easily access to the index. Dato che usiamo un sottoinsieme\n",
    "# di folder di LineMOD\n",
    "index_dict = dict()\n",
    "for index, elem in enumerate(class_names):\n",
    "    index_dict[int(elem)] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3c7b5",
   "metadata": {},
   "source": [
    "Create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_df = create_dataset_YOLO(number_classes, train_samples, validation_samples, test_samples, index_dict, path, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880b20d",
   "metadata": {},
   "source": [
    "Visualize dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cebb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import load_dataset_distribution\n",
    "\n",
    "load_dataset_distribution(counter_df, index_dict, number_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede843b",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b007448",
   "metadata": {},
   "source": [
    "Visualize depth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import load_depth_image\n",
    "\n",
    "folder = \"01\"\n",
    "object_name = \"0000\"\n",
    "img = load_depth_image(f\"./datasets/linemod/DenseFusion/Linemod_preprocessed/data/{folder}/depth/{object_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8a540",
   "metadata": {},
   "source": [
    "Plot the patch of first object of the image, it reads from the ground truth file containing also multiple objects in one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import load_depth_patch\n",
    "\n",
    "load_depth_patch(path, folder, object_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab338446",
   "metadata": {},
   "source": [
    "Get data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DataLoaderCollating import rgb_collate_fn\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=rgb_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=rgb_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=rgb_collate_fn)\n",
    "print(f\"Training loader: {len(train_loader)}\")\n",
    "print(f\"Validation loader: {len(val_loader)}\")\n",
    "print(f\"Test loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b86ad",
   "metadata": {},
   "source": [
    "Plot one batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef53038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import plot_batch_data\n",
    "\n",
    "plot_batch_data(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80313348",
   "metadata": {},
   "source": [
    "## Training YOLO (Object Detection model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_YOLO import train_YOLO\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "IMG_SIZE = 640\n",
    "\n",
    "train_YOLO(path, epochs, batch_size, device, IMG_SIZE) # train model and save it to checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d7a82",
   "metadata": {},
   "source": [
    "Validate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18df963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_YOLO import evaluate_YOLO\n",
    "\n",
    "evaluate_YOLO(path, epochs, batch_size, IMG_SIZE, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425354d6",
   "metadata": {},
   "source": [
    "## Pose Estimator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465dd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PosePredictorModel import PosePredictorModel\n",
    "from models.PosePredictorModelAlternative import PosePredictorModelAlternative\n",
    "from PoseEstimationTrainer import PoseEstimationTrainer\n",
    "from models.ADDMetric import ADDMetric\n",
    "from utils.pose_plot import plotPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84448d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DataLoaderCollating import pointcloud_collate_fn_baseline\n",
    "\n",
    "config = {\n",
    "    \"project_name\": \"baseline_quaternion\",\n",
    "    \"experiment_name\": \"mse_loss_2_cosine_mlp_complete\",\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 52,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"backbone\": \"resnet18\",\n",
    "    \"hidden_dim\": 512,\n",
    "    \"img_size\": 224,\n",
    "    \"alpha\": 1.0,\n",
    "    \"beta\": 1.0,\n",
    "    \"add_threshold\": 0.1,\n",
    "    \"symmetric_objects\": [\"10\",\"11\"],\n",
    "    \"name_saved_file\": \"mse_loss_2_cosine_mlp_complete\"\n",
    "}\n",
    "\n",
    "MODELS_DIR = \"./datasets/linemod/DenseFusion/Linemod_preprocessed/models\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Configuration: {config}\")\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=pointcloud_collate_fn_baseline)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=pointcloud_collate_fn_baseline)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, collate_fn=pointcloud_collate_fn_baseline)\n",
    "\n",
    "# Model\n",
    "model = PosePredictorModel(\n",
    "    backbone=config[\"backbone\"],\n",
    "    hidden_dim=config[\"hidden_dim\"]\n",
    ").to(device)\n",
    "\n",
    "# model = PosePredictorModelAlternative(backbone=config[\"backbone\"],hidden_dim=config[\"hidden_dim\"]).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "if COMET_ML:\n",
    "    experiment = comet_ml.start(\n",
    "        api_key=\"<YOUR_API>\",\n",
    "        project_name=config['project_name'],\n",
    "        experiment_config=comet_ml.ExperimentConfig(\n",
    "            name=config[\"experiment_name\"],\n",
    "            parse_args=False)\n",
    "    )\n",
    "\n",
    "    experiment.log_parameters(config)\n",
    "else:\n",
    "    experiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e781f",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME = True # set to False if needed\n",
    "\n",
    "checkpoint = None\n",
    "if RESUME:\n",
    "    checkpoint = torch.load(f\"./checkpoints/baseline_best_result.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "trainer = PoseEstimationTrainer(model, train_loader, val_loader, device=device, config=config, experiment=experiment, resume_optimizer=True, checkpoint=checkpoint)\n",
    "trainer.train(num_epochs=config[\"num_epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b2e05",
   "metadata": {},
   "source": [
    "Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"{path}/checkpoints/baseline_best_result.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "add_metric = ADDMetric(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    test_loader=test_loader,\n",
    "    models_3D_dir=MODELS_DIR,\n",
    "    symmetric_objects=config[\"symmetric_objects\"],\n",
    "    device=DEVICE,\n",
    "    experiment=experiment,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Evaluating with ADD metric...\")\n",
    "add_score, accuracy, detailed_results = add_metric.evaluate_model_with_add()\n",
    "\n",
    "\n",
    "print(f\"\\nFinal Results:\\nADD Score: {add_score:.4f}\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da526922",
   "metadata": {},
   "source": [
    "Visualize inference of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0389b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pose_plot import plotPose\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    images = batch['rgb'].to(device)\n",
    "    gt_trans = batch['translation']\n",
    "    gt_rot = batch['rotation']\n",
    "    object_ids = batch['obj_id']\n",
    "    sample_id = batch[\"sample_id\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_trans, pred_rot = model(images)\n",
    "        pred_trans = pred_trans\n",
    "        pred_rot = pred_rot\n",
    "       \n",
    "        for i in range(len(images)):\n",
    "            if i == 0:\n",
    "                img_path = f\"{path}/datasets/linemod/DenseFusion/Linemod_preprocessed/data/{sample_id[i][0]:02d}/rgb/{sample_id[i][1]:04d}.png\"\n",
    "\n",
    "                plotPose(img_path, gt_trans[i], gt_rot[i], pred_trans[i], pred_rot[i], experiment, cam_K)\n",
    "print(f\"Plot saved on comet_ml in project: {config['project_name']}, experiment: {config['experiment_name']}\")\n",
    "\n",
    "if COMET_ML:\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e98d2b",
   "metadata": {},
   "source": [
    "## Inference Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e59c50",
   "metadata": {},
   "source": [
    "Inference on test set using ```YOLO```, one image at a time. The ```ADD``` metric is also computed, so ground truth pose is required. It creates training, validation and test sets.\n",
    "\n",
    "Only the best baseline model is used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inferenceBaseline import inference_baseline\n",
    "\n",
    "inference_baseline(class_names=class_names, cam_K=cam_K, device=device, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218dd776",
   "metadata": {},
   "source": [
    "## Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3463ed4",
   "metadata": {},
   "source": [
    "Compare images in ```rgb``` and ```mask``` and analyze if there are images that are only in one of the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_exploration import compare_rgb_mask_in_data\n",
    "\n",
    "compare_rgb_mask_in_data(\"./datasets/linemod/DenseFusion/Linemod_preprocessed/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ff0bd",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741495dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.CustomDataset import CustomDataset\n",
    "\n",
    "dataset_root = \"./datasets/linemod/DenseFusion/Linemod_preprocessed/\"\n",
    "\n",
    "train_dataset = CustomDataset(dataset_root, split='train', device=device, cam_K=cam_K)\n",
    "image_mean, image_std = train_dataset.get_image_mean_std()\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "\n",
    "val_dataset = CustomDataset(dataset_root, split='validation', device=device, cam_K = cam_K, img_mean = image_mean, img_std = image_std)\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "\n",
    "test_dataset = CustomDataset(dataset_root, split='test', device=device, cam_K = cam_K, img_mean = image_mean, img_std = image_std)\n",
    "print(f'Testing samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2427a65",
   "metadata": {},
   "source": [
    "Get dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af010d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DataLoaderCollating import pointcloud_collate_fn\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=pointcloud_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=pointcloud_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=pointcloud_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce36f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.PoseEstimationPipeline import PoseEstimationPipeline\n",
    "from PoseTrainer import PoseTrainer\n",
    "from models.PoseLossExtension import PoseLossExtension\n",
    "from models.ADDMetricExtension import ADDMetricExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882640ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project_name\": \"pointnet\",\n",
    "    \"experiment_name\": \"HiG\",\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 90,\n",
    "    \"learning_rate\": 1.0e-04,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"backbone\": \"resnet18\",\n",
    "    \"hidden_dim\": 512,\n",
    "    \"img_size\": 224,\n",
    "    \"alpha\": 1.0,\n",
    "    \"beta\": 1.0,\n",
    "    \"add_threshold\": 0.1,\n",
    "    \"symmetric_objects\": [\"10\",\"11\"],\n",
    "    \"name_saved_file\": \"HiG\",\n",
    "    \"geometric_dims\" : [64,128,256],\n",
    "    \"fusion_dim\" : 128,\n",
    "    \"num_run_plotPose\": 1\n",
    "}\n",
    "\n",
    "MODELS_DIR = \"./datasets/linemod/DenseFusion/Linemod_preprocessed/models\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Configuration: {config}\")\n",
    "\n",
    "# model\n",
    "model = PoseEstimationPipeline(fx=cam_K[0],fy=cam_K[4],cx=cam_K[2],cy=cam_K[5]).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "if COMET_ML:\n",
    "    experiment = comet_ml.start(\n",
    "        api_key=\"<YOUR_API>\",\n",
    "        project_name=config['project_name'],\n",
    "        experiment_config=comet_ml.ExperimentConfig(\n",
    "            name=config[\"experiment_name\"],\n",
    "            parse_args=False)\n",
    "    )\n",
    "\n",
    "    experiment.log_parameters(config)\n",
    "else:\n",
    "    experiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc2e5b",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME = True # set to False if needed\n",
    "\n",
    "checkpoint = None\n",
    "if RESUME:\n",
    "    checkpoint = torch.load(f\"./checkpoints/HiG_Resnet18_bs16.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "trainer = PoseTrainer(model, class_names, train_loader, val_loader, device=device, config=config, experiment= experiment, resume_optimizer=True, checkpoint=checkpoint)\n",
    "trainer.train(num_epochs=config[\"num_epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3423a",
   "metadata": {},
   "source": [
    "Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2074b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"./checkpoints/HiG_Resnet18_bs16.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "add_metric = ADDMetricExtension(\n",
    "    model=model,\n",
    "    class_names=class_names,\n",
    "    test_loader=test_loader,\n",
    "    models_3D_dir=MODELS_DIR,\n",
    "    symmetric_objects=config[\"symmetric_objects\"],\n",
    "    device=device,\n",
    "    experiment= experiment,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Evaluating with ADD metric...\")\n",
    "add_score, accuracy, detailed_results = add_metric.evaluate_model_with_add()\n",
    "\n",
    "print(f\"\\nFinal Results:\\nADD Score: {add_score:.4f}\\nAccuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178242a",
   "metadata": {},
   "source": [
    "Visualize inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pose_plot import plotPose\n",
    "\n",
    "criterion = PoseLossExtension(class_names=class_names,device=device)\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    gt_trans = batch['translation']\n",
    "    gt_rot = batch['rotation']\n",
    "    object_ids = batch['obj_id']\n",
    "    sample_id = batch[\"sample_id\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pixel_rotations_norm, pixel_translations, pixel_confidences = model(batch)\n",
    "        loss, r, t = criterion(pixel_rotations_norm, pixel_translations, pixel_confidences, gt_trans, gt_rot, object_ids)\n",
    "\n",
    "        for i in range(len(object_ids)):\n",
    "            if i == 0:\n",
    "                img_path = f\"./datasets/linemod/DenseFusion/Linemod_preprocessed/data/{sample_id[i][0]:02d}/rgb/{sample_id[i][1]:04d}.png\"\n",
    "                plotPose(img_path, gt_trans[i], gt_rot[i], t[i], r[i], experiment=experiment, camera_intrinsics=cam_K)\n",
    "print(f\"Plot saved on comet_ml in project: {config['project_name']}, experiment: {config['experiment_name']}\")\n",
    "\n",
    "if COMET_ML:\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130325e8",
   "metadata": {},
   "source": [
    "## Inference Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9ac74",
   "metadata": {},
   "source": [
    "Perform inference on test set using ```YOLO```, but an object detection model is used instead of ground truth info. The ```ADD``` metric is also computed,\n",
    "so ground truth pose is required. It creates training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inferenceExtension import inference_extension\n",
    "\n",
    "inference_extension(class_names=class_names, cam_K=cam_K, device=device, path=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningAndDeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
